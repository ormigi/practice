{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f051114a-d227-4ff2-80c8-ba20bcdce873",
   "metadata": {},
   "source": [
    "## Integration of Google BigQuery DB with Databricks to enable seamless querying, processing, and analysis of large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c3f5b-4bd4-4afd-98b8-f4253a7e0f32",
   "metadata": {},
   "source": [
    "## Google BigQuery integration with Databricks to enable seamless querying, processing, and analysis of large datasets.\n",
    "\n",
    "Applications: ETL workflows across BigQuery & Databricks  * Analyzing large datasets using Spark & ML tools     *   Querying BigQuery data using SQL in Databricks   *   Optimizing cloud-based data pipelines\n",
    "\n",
    "## Other applications:  Real-time analytics, streaming data from BigQuery into Databricks  or  Machine Learning, by using Databricks MLflow on BigQuery datasets, ETL Pipelines for extracting, transforming, and loading data from BigQuery, BI Dashboards  for Power BI or Tableau integration with Databricks & BigQuery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb2607-c2a3-4bbf-9ea4-d0626c059fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Installing Required Packages\n",
    "%pip install google-cloud-bigquery pandas pybigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a449fed-19c7-4994-8e26-8412e0884e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Authentication\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/dbfs/FileStore/service_key.json\"\n",
    "\n",
    "# or just set credentials directly in Databricks\n",
    "spark.conf.set(\"google.cloud.auth.service.account.json.keyfile\", \"/dbfs/FileStore/service_key.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1a896-408e-48b0-9bd1-bb11bf80b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BigQuery Data into a Pandas DataFrame\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "client = bigquery.Client()\n",
    "query = \"\"\"\n",
    "SELECT journal, COUNT(*) AS Freq\n",
    "FROM `covid_research_db.metadata_2020_07_01`\n",
    "WHERE journal IS NOT NULL\n",
    "GROUP BY journal\n",
    "ORDER BY Freq DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(query).to_dataframe()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57017ab-d387-4e40-957d-9acfcd4d6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BigQuery Data into a Spark DataFrame\n",
    "df_spark = spark.read.format(\"bigquery\") \\\n",
    "    .option(\"credentialsFile\", \"/dbfs/FileStore/service_key.json\") \\\n",
    "    .option(\"project\", \"your-gcp-project-id\") \\\n",
    "    .option(\"dataset\", \"covid_research_db\") \\\n",
    "    .option(\"table\", \"metadata_2020_07_01\") \\\n",
    "    .load()\n",
    "\n",
    "df_spark.createOrReplaceTempView(\"bigquery_table\")\n",
    "\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10418df9-60b9-4376-b354-15149da88f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run SQL Query in Databricks\n",
    "result = spark.sql(\"\"\"\n",
    "SELECT journal, COUNT(*) AS Freq\n",
    "FROM bigquery_table\n",
    "GROUP BY journal\n",
    "ORDER BY Freq DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3f1f6-e20e-4715-aa22-8a76eea53fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Write Data Back to BigQuery: \n",
    "df_spark.write.format(\"bigquery\") \\\n",
    "    .option(\"credentialsFile\", \"/dbfs/FileStore/service_key.json\") \\\n",
    "    .option(\"project\", \"your-gcp-project-id\") \\\n",
    "    .option(\"dataset\", \"covid_research_db\") \\\n",
    "    .option(\"table\", \"processed_results\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473013e-cdfa-4dbf-a19d-5f479af8f7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b0265-f2f3-416b-9ca2-ad1bb95b6d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8b6e2-74f4-416d-a33c-9b5f08042ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
